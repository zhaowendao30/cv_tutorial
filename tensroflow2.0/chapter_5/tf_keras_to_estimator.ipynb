{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "sys.version_info(major=3, minor=7, micro=3, releaselevel='final', serial=0)\n",
      "matplotlib 3.1.1\n",
      "numpy 1.17.3\n",
      "pandas 0.25.3\n",
      "sklearn 0.21.3\n",
      "tensorflow 2.0.0\n",
      "tensorflow_core.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1         1  female  38.0                   1      0  71.2833  First        C   \n",
      "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3         1  female  35.0                   1      0  53.1000  First        C   \n",
      "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "   survived     sex   age  n_siblings_spouses  parch     fare   class  \\\n",
      "0         0    male  35.0                   0      0   8.0500   Third   \n",
      "1         0    male  54.0                   0      0  51.8625   First   \n",
      "2         1  female  58.0                   0      0  26.5500   First   \n",
      "3         1  female  55.0                   0      0  16.0000  Second   \n",
      "4         1    male  34.0                   0      0  13.0000  Second   \n",
      "\n",
      "      deck  embark_town alone  \n",
      "0  unknown  Southampton     y  \n",
      "1        E  Southampton     y  \n",
      "2        C  Southampton     y  \n",
      "3  unknown  Southampton     y  \n",
      "4        D  Southampton     y  \n"
     ]
    }
   ],
   "source": [
    "# https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
    "# https://storage.googleapis.com/tf-datasets/titanic/eval.csv\n",
    "# 定义训练集和测试集的路径\n",
    "train_file = \"./data/titanic/train.csv\"\n",
    "eval_file = \"./data/titanic/eval.csv\"\n",
    "\n",
    "# 使用pandas读取这两个数据集\n",
    "# pandas的csv API可以读取解析csv文件\n",
    "train_df = pd.read_csv(train_file)\n",
    "eval_df = pd.read_csv(eval_file)\n",
    "\n",
    "# 使用pandas读取前五条数据\n",
    "print(train_df.head())\n",
    "print(eval_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1  female  38.0                   1      0  71.2833  First        C   \n",
      "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3  female  35.0                   1      0  53.1000  First        C   \n",
      "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "      sex   age  n_siblings_spouses  parch     fare   class     deck  \\\n",
      "0    male  35.0                   0      0   8.0500   Third  unknown   \n",
      "1    male  54.0                   0      0  51.8625   First        E   \n",
      "2  female  58.0                   0      0  26.5500   First        C   \n",
      "3  female  55.0                   0      0  16.0000  Second  unknown   \n",
      "4    male  34.0                   0      0  13.0000  Second        D   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     y  \n",
      "1  Southampton     y  \n",
      "2  Southampton     y  \n",
      "3  Southampton     y  \n",
      "4  Southampton     y  \n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: survived, dtype: int64\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_train = train_df.pop('survived')\n",
    "y_eval = eval_df.pop('survived')\n",
    "\n",
    "# head:默认取前五条数据\n",
    "print(train_df.head())\n",
    "print(eval_df.head())\n",
    "print(y_train.head())\n",
    "print(y_eval.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.631308</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>34.385399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.511818</td>\n",
       "      <td>1.151090</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>54.597730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  n_siblings_spouses       parch        fare\n",
       "count  627.000000          627.000000  627.000000  627.000000\n",
       "mean    29.631308            0.545455    0.379585   34.385399\n",
       "std     12.511818            1.151090    0.792999   54.597730\n",
       "min      0.750000            0.000000    0.000000    0.000000\n",
       "25%     23.000000            0.000000    0.000000    7.895800\n",
       "50%     28.000000            0.000000    0.000000   15.045800\n",
       "75%     35.000000            1.000000    0.000000   31.387500\n",
       "max     80.000000            8.000000    5.000000  512.329200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 利用pandas查看数据集中的一些统计量\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(627, 9) (264, 9)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, eval_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a3bf4f89b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# .age:将age上的值取出来\n",
    "# .hist:画直方图\n",
    "# bins:将这些值分为多少份\n",
    "train_df.age.hist(bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a3c0896518>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# value_counts:值的数目\n",
    "# barh:横向图， barv:纵向图\n",
    "train_df.sex.value_counts().plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a3c091d438>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# class与保留字冲突\n",
    "train_df['class'].value_counts().plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a3c097b080>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 男性中有百分之多少获救，女性中有百分之多少获救\n",
    "# concat:将数据集合并， axis:定义纬度\n",
    "# groupby:分组\n",
    "pd.concat([train_df, y_train], axis = 1).groupby('sex').survived.mean().plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex ['male' 'female']\n",
      "n_siblings_spouses [1 0 3 4 2 5 8]\n",
      "parch [0 1 2 5 3 4]\n",
      "class ['Third' 'First' 'Second']\n",
      "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
      "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
      "alone ['n' 'y']\n"
     ]
    }
   ],
   "source": [
    "# categorical_columns:离散特征 -> one-hot\n",
    "# numeric_columns:连续特征 -> 直接用\n",
    "\n",
    "categorical_columns = ['sex', 'n_siblings_spouses', 'parch', 'class', \n",
    "                      'deck', 'embark_town', 'alone']\n",
    "numeric_columns = ['age', 'fare']\n",
    "\n",
    "feature_columns = []\n",
    "\n",
    "# 对离散特征的处理\n",
    "for categorical_column in categorical_columns:\n",
    "    # 获得离散特征的所有可能的取值\n",
    "    vocab = train_df[categorical_column].unique()\n",
    "    print(categorical_column, vocab)\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.indicator_column(\n",
    "            tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "                categorical_column, vocab)))\n",
    "\n",
    "# 对连续特征的处理\n",
    "for categorical_column in numeric_columns:\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.numeric_column(\n",
    "            categorical_column, dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建dataset\n",
    "# shuffle:是否混排\n",
    "def make_dataset(data_df, label_df, epochs = 10, shuffle = True,\n",
    "                batch_size = 32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dict(data_df), label_df))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset(train_df, y_train, batch_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sex': <tf.Tensor: id=89, shape=(5,), dtype=string, numpy=array([b'male', b'male', b'male', b'male', b'male'], dtype=object)>, 'age': <tf.Tensor: id=81, shape=(5,), dtype=float64, numpy=array([28., 45., 28., 24., 32.])>, 'n_siblings_spouses': <tf.Tensor: id=87, shape=(5,), dtype=int32, numpy=array([0, 1, 0, 2, 0])>, 'parch': <tf.Tensor: id=88, shape=(5,), dtype=int32, numpy=array([0, 0, 0, 0, 0])>, 'fare': <tf.Tensor: id=86, shape=(5,), dtype=float64, numpy=array([ 7.25 , 83.475,  7.225, 24.15 ,  8.05 ])>, 'class': <tf.Tensor: id=83, shape=(5,), dtype=string, numpy=array([b'Third', b'First', b'Third', b'Third', b'Third'], dtype=object)>, 'deck': <tf.Tensor: id=84, shape=(5,), dtype=string, numpy=array([b'unknown', b'C', b'unknown', b'unknown', b'E'], dtype=object)>, 'embark_town': <tf.Tensor: id=85, shape=(5,), dtype=string, numpy=\n",
      "array([b'Southampton', b'Southampton', b'Cherbourg', b'Southampton',\n",
      "       b'Southampton'], dtype=object)>, 'alone': <tf.Tensor: id=82, shape=(5,), dtype=string, numpy=array([b'y', b'n', b'y', b'n', b'y'], dtype=object)>} tf.Tensor([0 0 0 0 1], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# import pprint\n",
    "for x, y in train_dataset.take(1):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_features_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[28.]\n",
      " [59.]\n",
      " [14.]\n",
      " [50.]\n",
      " [57.]]\n",
      "WARNING:tensorflow:Layer dense_features_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# keras.layers.DenseFeature:将feature_columns的规则应用到dataset每组数据上去\n",
    "# feature_columns是一组对features进行变换的规则\n",
    "for x, y in train_dataset.take(1):\n",
    "    age_column = feature_columns[7]\n",
    "    gender_column = feature_columns[0]\n",
    "    print(keras.layers.DenseFeatures(age_column)(x).numpy())\n",
    "    print(keras.layers.DenseFeatures(gender_column)(x).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_features_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[ 36.       0.       1.       1.       0.       0.       1.       0.\n",
      "    0.       0.       0.       0.       0.       0.       1.       0.\n",
      "    0.       0.       7.8958   0.       1.       0.       0.       0.\n",
      "    0.       0.       1.       0.       0.       0.       0.       0.\n",
      "    1.       0.    ]\n",
      " [ 28.       1.       0.       1.       0.       0.       1.       0.\n",
      "    0.       0.       0.       0.       0.       0.       0.       0.\n",
      "    1.       0.      15.5      1.       0.       0.       0.       0.\n",
      "    0.       0.       1.       0.       0.       0.       0.       0.\n",
      "    1.       0.    ]\n",
      " [ 28.       0.       1.       0.       1.       0.       1.       0.\n",
      "    0.       0.       0.       0.       0.       0.       0.       1.\n",
      "    0.       0.     227.525    0.       1.       0.       0.       0.\n",
      "    0.       0.       1.       0.       0.       0.       0.       0.\n",
      "    1.       0.    ]\n",
      " [ 24.       0.       1.       0.       0.       1.       0.       0.\n",
      "    0.       0.       0.       0.       1.       0.       1.       0.\n",
      "    0.       0.      13.       0.       1.       0.       0.       0.\n",
      "    0.       0.       1.       0.       0.       0.       0.       0.\n",
      "    0.       1.    ]\n",
      " [ 44.       1.       0.       0.       1.       0.       0.       1.\n",
      "    0.       0.       0.       0.       0.       0.       0.       0.\n",
      "    1.       0.      90.       0.       0.       0.       0.       1.\n",
      "    0.       0.       1.       0.       0.       0.       0.       0.\n",
      "    1.       0.    ]]\n"
     ]
    }
   ],
   "source": [
    "# keras.layers.DenseFeature:将feature_columns的规则应用到dataset每组数据上去\n",
    "# feature_columns是一组对features进行变换的规则\n",
    "for x, y in train_dataset.take(1):\n",
    "    print(keras.layers.DenseFeatures(feature_columns)(x).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.DenseFeatures(feature_columns),\n",
    "    keras.layers.Dense(100, activation = 'relu'),\n",
    "    keras.layers.Dense(100, activation = 'relu'),\n",
    "    keras.layers.Dense(2, activation = 'softmax'),\n",
    "])\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "             optimizer = keras.optimizers.SGD(lr = 0.01),\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sequential_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Train for 20 steps, validate for 8 steps\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 4s 207ms/step - loss: 1.9487 - accuracy: 0.5875 - val_loss: 0.7559 - val_accuracy: 0.5938\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.8404 - accuracy: 0.6750 - val_loss: 1.4403 - val_accuracy: 0.6250\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.7188 - accuracy: 0.6703 - val_loss: 0.6662 - val_accuracy: 0.6992\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6440 - accuracy: 0.6547 - val_loss: 0.6351 - val_accuracy: 0.6602\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6231 - accuracy: 0.6922 - val_loss: 0.6505 - val_accuracy: 0.6367\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6063 - accuracy: 0.6875 - val_loss: 0.7773 - val_accuracy: 0.6250\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6205 - accuracy: 0.6812 - val_loss: 0.6447 - val_accuracy: 0.6328\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5988 - accuracy: 0.6781 - val_loss: 0.6006 - val_accuracy: 0.6836\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.6092 - accuracy: 0.6672 - val_loss: 0.5780 - val_accuracy: 0.7031\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5863 - accuracy: 0.6906 - val_loss: 0.5807 - val_accuracy: 0.6914\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5857 - accuracy: 0.6859 - val_loss: 0.5740 - val_accuracy: 0.7031\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6040 - accuracy: 0.6875 - val_loss: 0.5996 - val_accuracy: 0.6367\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6004 - accuracy: 0.6750 - val_loss: 0.5782 - val_accuracy: 0.7031\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5878 - accuracy: 0.6844 - val_loss: 0.6203 - val_accuracy: 0.6602\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5674 - accuracy: 0.7031 - val_loss: 0.5766 - val_accuracy: 0.6875\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5840 - accuracy: 0.7000 - val_loss: 0.5724 - val_accuracy: 0.6758\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5690 - accuracy: 0.7016 - val_loss: 0.5857 - val_accuracy: 0.6602\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5595 - accuracy: 0.7156 - val_loss: 0.5622 - val_accuracy: 0.6836\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5840 - accuracy: 0.6797 - val_loss: 0.5573 - val_accuracy: 0.6836\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5957 - accuracy: 0.6938 - val_loss: 0.5550 - val_accuracy: 0.7227\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5516 - accuracy: 0.7219 - val_loss: 0.5496 - val_accuracy: 0.7070\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5727 - accuracy: 0.7203 - val_loss: 0.5461 - val_accuracy: 0.7031\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5640 - accuracy: 0.7016 - val_loss: 0.5732 - val_accuracy: 0.6719\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5611 - accuracy: 0.7094 - val_loss: 0.5472 - val_accuracy: 0.7109\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5732 - accuracy: 0.6953 - val_loss: 0.6242 - val_accuracy: 0.6641\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6037 - accuracy: 0.6781 - val_loss: 0.6042 - val_accuracy: 0.6992\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5686 - accuracy: 0.7094 - val_loss: 0.5889 - val_accuracy: 0.7188\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5597 - accuracy: 0.7266 - val_loss: 0.5489 - val_accuracy: 0.7070\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5514 - accuracy: 0.7453 - val_loss: 0.5425 - val_accuracy: 0.6992\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5537 - accuracy: 0.7266 - val_loss: 0.5453 - val_accuracy: 0.7031\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5886 - accuracy: 0.6922 - val_loss: 0.5406 - val_accuracy: 0.6797\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5514 - accuracy: 0.7094 - val_loss: 0.5953 - val_accuracy: 0.6914\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5860 - accuracy: 0.6984 - val_loss: 0.5398 - val_accuracy: 0.7070\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5412 - accuracy: 0.7250 - val_loss: 0.5866 - val_accuracy: 0.7070\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5689 - accuracy: 0.7109 - val_loss: 0.5355 - val_accuracy: 0.6992\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5317 - accuracy: 0.7453 - val_loss: 0.5390 - val_accuracy: 0.7070\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5871 - accuracy: 0.7078 - val_loss: 0.5538 - val_accuracy: 0.7383\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5415 - accuracy: 0.7312 - val_loss: 0.5470 - val_accuracy: 0.7109\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5124 - accuracy: 0.7469 - val_loss: 0.5317 - val_accuracy: 0.7070\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5486 - accuracy: 0.7281 - val_loss: 0.7899 - val_accuracy: 0.5352\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5497 - accuracy: 0.7172 - val_loss: 0.5473 - val_accuracy: 0.7188\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.7484 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5483 - accuracy: 0.7219 - val_loss: 0.5165 - val_accuracy: 0.7305\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5390 - accuracy: 0.7359 - val_loss: 0.5893 - val_accuracy: 0.6953\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5167 - accuracy: 0.7391 - val_loss: 0.5831 - val_accuracy: 0.7148\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5437 - accuracy: 0.7281 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5314 - accuracy: 0.7297 - val_loss: 0.5147 - val_accuracy: 0.7305\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5975 - accuracy: 0.7234 - val_loss: 0.6361 - val_accuracy: 0.6680\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5300 - accuracy: 0.7500 - val_loss: 0.5546 - val_accuracy: 0.7148\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5278 - accuracy: 0.7391 - val_loss: 0.5218 - val_accuracy: 0.7148\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5451 - accuracy: 0.7312 - val_loss: 0.6172 - val_accuracy: 0.6875\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5225 - accuracy: 0.7375 - val_loss: 0.5545 - val_accuracy: 0.7031\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5570 - accuracy: 0.7250 - val_loss: 0.5627 - val_accuracy: 0.7109\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5219 - accuracy: 0.7516 - val_loss: 0.6042 - val_accuracy: 0.6992\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5483 - accuracy: 0.7234 - val_loss: 0.5087 - val_accuracy: 0.7578\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5231 - accuracy: 0.7391 - val_loss: 0.5093 - val_accuracy: 0.7266\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5369 - accuracy: 0.7437 - val_loss: 0.5298 - val_accuracy: 0.7344\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5307 - accuracy: 0.7328 - val_loss: 0.5026 - val_accuracy: 0.7461\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5213 - accuracy: 0.7469 - val_loss: 0.5146 - val_accuracy: 0.7266\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5701 - accuracy: 0.7359 - val_loss: 0.5570 - val_accuracy: 0.6875\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5493 - accuracy: 0.7375 - val_loss: 0.5130 - val_accuracy: 0.7266\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5424 - accuracy: 0.7203 - val_loss: 0.5230 - val_accuracy: 0.7305\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5590 - accuracy: 0.7453 - val_loss: 0.5270 - val_accuracy: 0.7227\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5194 - accuracy: 0.7734 - val_loss: 0.5205 - val_accuracy: 0.7344\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.5341 - accuracy: 0.7203 - val_loss: 0.5309 - val_accuracy: 0.7344\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5267 - accuracy: 0.7594 - val_loss: 0.5693 - val_accuracy: 0.7109\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5133 - accuracy: 0.7484 - val_loss: 0.6922 - val_accuracy: 0.6367\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5321 - accuracy: 0.7391 - val_loss: 0.6386 - val_accuracy: 0.6875\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5499 - accuracy: 0.7406 - val_loss: 0.5891 - val_accuracy: 0.6992\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5207 - accuracy: 0.7469 - val_loss: 0.4997 - val_accuracy: 0.7383\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5269 - accuracy: 0.7437 - val_loss: 0.5139 - val_accuracy: 0.7266\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5752 - accuracy: 0.7297 - val_loss: 0.5420 - val_accuracy: 0.7266\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5399 - accuracy: 0.7656 - val_loss: 0.5886 - val_accuracy: 0.6328\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5412 - accuracy: 0.7500 - val_loss: 0.5118 - val_accuracy: 0.7461\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5261 - accuracy: 0.7578 - val_loss: 0.6155 - val_accuracy: 0.6992\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5445 - accuracy: 0.7344 - val_loss: 0.5161 - val_accuracy: 0.7383\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5310 - accuracy: 0.7375 - val_loss: 0.4977 - val_accuracy: 0.7539\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5285 - accuracy: 0.7453 - val_loss: 0.5066 - val_accuracy: 0.7461\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4967 - accuracy: 0.7688 - val_loss: 0.5469 - val_accuracy: 0.7227\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5248 - accuracy: 0.7656 - val_loss: 0.4983 - val_accuracy: 0.7461\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5058 - accuracy: 0.7750 - val_loss: 0.6130 - val_accuracy: 0.7031\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5072 - accuracy: 0.7531 - val_loss: 0.5081 - val_accuracy: 0.7344\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5087 - accuracy: 0.7641 - val_loss: 0.5050 - val_accuracy: 0.7227\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5157 - accuracy: 0.7625 - val_loss: 0.4914 - val_accuracy: 0.7500\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5225 - accuracy: 0.7656 - val_loss: 0.5039 - val_accuracy: 0.7461\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5218 - accuracy: 0.7516 - val_loss: 0.5015 - val_accuracy: 0.7383\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5388 - accuracy: 0.7359 - val_loss: 0.4996 - val_accuracy: 0.7422\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5180 - accuracy: 0.7563 - val_loss: 0.4927 - val_accuracy: 0.7461\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5032 - accuracy: 0.7578 - val_loss: 0.5376 - val_accuracy: 0.7227\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5213 - accuracy: 0.7625 - val_loss: 0.5549 - val_accuracy: 0.7070\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5159 - accuracy: 0.7531 - val_loss: 0.5209 - val_accuracy: 0.6992\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5380 - accuracy: 0.7578 - val_loss: 0.5180 - val_accuracy: 0.7188\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5036 - accuracy: 0.7547 - val_loss: 0.4993 - val_accuracy: 0.7422\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4987 - accuracy: 0.7688 - val_loss: 0.5647 - val_accuracy: 0.7031\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5024 - accuracy: 0.7766 - val_loss: 0.5295 - val_accuracy: 0.7422\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5386 - accuracy: 0.7359 - val_loss: 0.4978 - val_accuracy: 0.7266\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5094 - accuracy: 0.7625 - val_loss: 0.5190 - val_accuracy: 0.7188\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5083 - accuracy: 0.7645 - val_loss: 1.0848 - val_accuracy: 0.3984\n",
      "Epoch 99/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
      " 0/20 [..............................] - ETA: 0s"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Empty training data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-c2ca621ec9e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                    \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                    \u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                    epochs = 100)\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m   \u001b[1;31m# End of an epoch.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m   \u001b[0maggregator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0maggregator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mfinalize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    138\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Empty training data.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Empty training data."
     ]
    }
   ],
   "source": [
    "# 1.model.fit\n",
    "# 2.model -> estimator -> train\n",
    "train_dataset = make_dataset(train_df, y_train, epochs  = 100)\n",
    "eval_dataset = make_dataset(eval_df, y_eval, epochs = 1, shuffle = False)\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data = eval_dataset,\n",
    "                   steps_per_epoch = 20,\n",
    "                   validation_steps = 8,\n",
    "                   epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Dell\\AppData\\Local\\Temp\\tmpuz1r0gxa\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "WARNING:tensorflow:You are creating an Estimator from a Keras model manually subclassed from `Model`, that was already called on some inputs (and thus already had weights). We are currently unable to preserve the model's state (its weights) as part of the estimator in this case. Be warned that the estimator has been created using a freshly initialized version of your model.\n",
      "Note that this doesn't affect the state of the model instance you passed as `keras_model` argument.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Dell\\\\AppData\\\\Local\\\\Temp\\\\tmpuz1r0gxa', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002C095E394A8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-f5e415866957>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 1. function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# 2. return  a.(features, labels) b. dataset ->(feature, label)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m estimator.train(input_fn = lambda: make_dataset(\n\u001b[0m\u001b[0;32m      5\u001b[0m     train_df, y_train, epochs = 100))\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py37\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py37\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1158\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1160\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py37\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1188\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[1;32m-> 1190\u001b[1;33m           features, labels, ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[0;32m   1191\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py37\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[1;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[0;32m   1146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1148\u001b[1;33m     \u001b[0mmodel_fn_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1149\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py37\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\keras.py\u001b[0m in \u001b[0;36mmodel_fn\u001b[1;34m(features, labels, mode)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m         optimizer_config=optimizer_config)\n\u001b[0m\u001b[0;32m    289\u001b[0m     \u001b[0mmodel_output_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;31m# We need to make sure that the output names of the last layer in the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py37\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\keras.py\u001b[0m in \u001b[0;36m_clone_and_build_model\u001b[1;34m(mode, keras_model, custom_objects, features, labels, optimizer_config)\u001b[0m\n\u001b[0;32m    225\u001b[0m       \u001b[0min_place_reset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mkeras_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m       \u001b[0moptimizer_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m       optimizer_config=optimizer_config)\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0msample_weight_tensors\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\keras\\models.py\u001b[0m in \u001b[0;36mclone_and_build_model\u001b[1;34m(model, input_tensors, target_tensors, custom_objects, compile_clone, in_place_reset, optimizer_iterations, optimizer_config)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[0mclone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m       \u001b[0mclone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m     if all([isinstance(clone, Sequential),\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\keras\\models.py\u001b[0m in \u001b[0;36mclone_model\u001b[1;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[0;32m    417\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     return _clone_sequential_model(\n\u001b[1;32m--> 419\u001b[1;33m         model, input_tensors=input_tensors, layer_fn=clone_function)\n\u001b[0m\u001b[0;32m    420\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m     return _clone_functional_model(\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\keras\\models.py\u001b[0m in \u001b[0;36m_clone_sequential_model\u001b[1;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[0;32m    336\u001b[0m       \u001b[0minput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m       \u001b[0morigin_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    985\u001b[0m                         sparse_tensor.SparseTensor)):\n\u001b[0;32m    986\u001b[0m     raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) +\n\u001b[1;32m--> 987\u001b[1;33m                      '`. Expected a symbolic tensor instance.')\n\u001b[0m\u001b[0;32m    988\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_keras_history'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance."
     ]
    }
   ],
   "source": [
    "estimator = keras.estimator.model_to_estimator(model)\n",
    "# 1. function\n",
    "# 2. return  a.(features, labels) b. dataset ->(feature, label)\n",
    "estimator.train(input_fn = lambda: make_dataset(\n",
    "    train_df, y_train, epochs = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
